{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems - MITXPro\n",
    "\n",
    "This is my solution for Case Study 4.1 of MITXPro Data Science and Big Data Analytics. This is a simple recomendation system using some of the MovieLens (http://grouplens.org/datasets/movielens) dataset. Specifically, the 100K dataset.\n",
    "\n",
    "Basically, I use population averages as a base case and then Alternating Least Squares (ALS) to implement a collaborative filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some libraries that implement many recommendaton algorithms (such as RecommenderLab and Graphlab-Create), but I decided to implement myself population and ALS algorithms. So, all I import is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      "user_id    100000 non-null int64\n",
      "item_id    100000 non-null int64\n",
      "rating     100000 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.3 MB\n"
     ]
    }
   ],
   "source": [
    "col_names = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "data = pd.read_table(\"u.data\", names=col_names)\n",
    "data = data.drop(\"timestamp\", 1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEZCAYAAABvpam5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4eZmeX2/wFvkznn4i9iUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79cd7d6610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hist(data, title=None):\n",
    "    \"\"\"Plot a histogram of ratings. This assumes ratings goes from 1 to 5.\n",
    "    \n",
    "    Args:\n",
    "        data (pandas DataFrame): Dataframe with a \"rating\" column.\n",
    "        \n",
    "        title (str): title of the graph\n",
    "    \"\"\"\n",
    "    plt.hist(data[\"rating\"],bins=np.arange(1,7) - 0.5, edgecolor='black', linewidth=1.1)\n",
    "    plt.xticks(np.arange(1,6))\n",
    "    if title != None:\n",
    "        plt.title(title)\n",
    "    plt.xlabel(\"Rating\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "hist(data, \"Original rating distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the sparcity of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparcity of the original dataframe: 6.30%\n"
     ]
    }
   ],
   "source": [
    "Number_Ratings = len(data)\n",
    "Number_Movies = len(np.unique(data[\"item_id\"]))\n",
    "Number_Users = len(np.unique(data[\"user_id\"]))\n",
    "\n",
    "print \"Sparcity of the original dataframe: %.2f%%\" % ( float(Number_Ratings)/(Number_Movies*Number_Users)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will subset the data to make it less sparse. The user specify a threshold in the number of observations and the data is subsetted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subSettingData(data, userThold, movieThold):\n",
    "    \"\"\"Select Users/Movies that have at least userThold/movieThold observations.\n",
    "    \n",
    "    Select Users that have at least userThold observation, and, after thresholding\n",
    "    users, select Movies that have at least movieThold observations.\n",
    "\n",
    "    Args:\n",
    "        data (pandas DataFrame): Dataframe with columns \"user_id\", \"item_id\",\n",
    "            \"rating\".\n",
    "        userThold (int): user observation threshold\n",
    "        movieThold (int): movie observation threshold\n",
    "        \n",
    "    Returns:\n",
    "        pandas DataFrame: subsetted Dataframe\n",
    "    \"\"\"\n",
    "    # thesholding users first\n",
    "    c={x: 0 for x in set(data['user_id'].values)}\n",
    "    for i in data['user_id'].values:\n",
    "        c[i]+=1\n",
    "    keepUsers=set(filter(lambda x: c[x] > userThold, c))\n",
    "    res=data[data['user_id'].isin(keepUsers)]\n",
    "    # then thesholding movies\n",
    "    c={x:0 for x in set(res['item_id'].values)}\n",
    "    for i in res['item_id'].values:\n",
    "        c[i]+=1\n",
    "    keepMovies=set(filter(lambda x: c[x] > movieThold, c))\n",
    "    res=res[res['item_id'].isin(keepMovies)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use a theshold of 50 in both user and movie observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = subSettingData(data, 50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sparcity was sensibly reduced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_Ratings2 = len(data2)\n",
    "Number_Movies2 = len(np.unique(data2[\"item_id\"]))\n",
    "Number_Users2 = len(np.unique(data2[\"user_id\"]))\n",
    "\n",
    "print \"Sparcity of the original dataframe: %.2f%%\" % ( float(Number_Ratings2)/(Number_Movies2*Number_Users2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the historgram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I create some dictionaries to map the user_id and item_id to matrices indices in the appropriate matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMaps(data):\n",
    "    \"\"\"return maps to/from user_id/item_id from/to matrix index\n",
    "    \n",
    "    This should be used with the full dataframe, i.e. before splitting\n",
    "    the dataframe into train, validation and test sets\n",
    "    \n",
    "    Args:\n",
    "        data(pandas Dataframe): dataframe with columns \"item_id\"\n",
    "            and \"user_id\"\n",
    "            \n",
    "    Returns:\n",
    "        tuple of four dictionaries, first maps users to matrix row\n",
    "        second maps movies to matrix columns, third maps row matrix\n",
    "        to user (inverse map of fist map) and fourth maps matrix\n",
    "        column to movies\n",
    "    \"\"\"\n",
    "    col2Movie={i:j for i,j in enumerate(np.unique(data[\"item_id\"]))}\n",
    "    movie2Col={col2Movie[i] : i for i in col2Movie}\n",
    "    row2User={i:j for i,j in enumerate(np.unique(data[\"user_id\"]))}\n",
    "    user2Row={row2User[i] : i for i in row2User}\n",
    "    return user2Row, movie2Col, row2User, col2Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user2Row, movie2Col, row2User, col2Movie = getMaps(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the less sparse dataframe is splited into train+validation (70% of the total) and test (30%) sets. Furthermore, the first set is splitted again into train (75%) and validation (25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming pdf is the pandas dataframe with the data\n",
    "trainValid2, test2 = train_test_split(data2, test_size = 0.3)\n",
    "train2, valid2 = train_test_split(trainValid2, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than using a library I decided implementing myself the population and a collaborative algorithms. Particularly, I implemented Alternating Least Squares (ALS) that is quite simple and intuitive. However, the implementation is not very efficient. It could be parallelized fairly easily. It only requires to invert a small matrix (k dimensional, where k is the number of chosen features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function implements the population tranning, where I use the trainning set to compute averages across movies and use those averages to fill in the remainder of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pop_train(nusers, nmovies, data):\n",
    "    \"\"\"this function train using the population averages. \n",
    "    \n",
    "    Args:\n",
    "        nusers (int): total number of users in the full set, i.e.\n",
    "            train+validation+test set\n",
    "        nmovies (int): total number of movies in the full set\n",
    "        data (pandas Dataframe): dataframe with the trainning set\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array : recommendation matrix completely filled.\n",
    "    \"\"\"\n",
    "    R=np.zeros((nusers, nmovies))\n",
    "    W=np.zeros_like(R)\n",
    "    for i,j,l in data.values:\n",
    "        R[user2Row[i], movie2Col[j]] = l\n",
    "        W[user2Row[i], movie2Col[j]] = 1 if l > 0 else 0\n",
    "    y=np.sum(R, axis=0)/np.sum(W, axis=0)\n",
    "    y=np.tile(y, (R.shape[0],1))\n",
    "    R[W==0]=y[W==0]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pop_predict(R, l):\n",
    "    \"\"\"using the matrix returned by pop_train predicts ratings of a list of pairs user\n",
    "       and movie.\n",
    "       \n",
    "    Args:\n",
    "        R (np.array): ratings matrix trained with pop_train\n",
    "        \n",
    "    Returns:\n",
    "        numpy.array: predicted labels yhat\n",
    "    \"\"\"\n",
    "    res=[]\n",
    "    for u, m in l:\n",
    "        res.append( R[user2Row[u], movie2Col[m]] )\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y,yhat):\n",
    "    \"\"\"compute rmse between two vectors\n",
    "    \n",
    "    Args:\n",
    "        y (np.array): true labels\n",
    "        yhat (np.array): prediction\n",
    "    \n",
    "    Returns:\n",
    "        float: rmse\n",
    "    \"\"\"\n",
    "    return np.sqrt( np.mean(np.power(y-yhat,2.0)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the population algorithm with the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is no need to fine tune the population algorithm I am using\n",
    "#   the train + validation sets to train it\n",
    "R2=pop_train(Number_Users2, Number_Movies2, trainValid2)\n",
    "yhat2=pop_predict(R2, test2.values[:,0:2])\n",
    "rmse(test2.values[:,2], yhat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Least Squares\n",
    "\n",
    "An intuitive description of Alternating Least Squares (ALS) is as follows:\n",
    "\n",
    "We want to compute a low rank (rank k) fatorization of the true (and complete) rating matrix $R$ (dimensions n by m, where n is the number of users, and m is the number of movies) as follows:\n",
    "\n",
    "$\\;\\;\\;X^T\\cdot Y=R$\n",
    "\n",
    "where $X$ is the user feature matrix (dimensions k by n) and $Y$ is the movie feature matrix (dimensions k by m).\n",
    "\n",
    "We can formulate this as an optimization problem of this form:\n",
    "\n",
    "$\\;\\;\\;min (X^T\\cdot Y - R)^2$\n",
    "\n",
    "But this is not convex, since we want to find both $X$ and $Y$. But if we knew $Y$, we could apply least squares to find X, and, in the other hand, if we knew $X$ we could apply least squares to find $Y$. This is basically what ALS does: it pretends to know one variable (at the beginning initializing it randomily) and solves for the other variable. Next step, the variables invert roles and a new least squares is used.\n",
    "\n",
    "Before presenting the formulation, we need to realize that what we have is not $R$ but an incomplete matrix. If you think of a particular user $u$, what we have is:\n",
    "\n",
    "$\\;\\;\\;W_u \\cdot Y^T \\cdot x_u=W_u \\cdot r_u^T$\n",
    "\n",
    "where $x_u$ is the column of $X$ corresponding to user $u$, $r_u$ is the row of $R$ also corresponding to $u$ and $W_u$ is a diagonal matrix with ones only in the possitions where we actually have observations of $u$. In the same way, for movies we have:\n",
    "\n",
    "$\\;\\;\\;W_m \\cdot X^T\\cdot y_m=W_m \\cdot r_m$\n",
    "\n",
    "where $y_m$ is the column of $Y$ corresponding to movie $m$, $r_m$ is the column of $R$ also corresponding to $m$ and $W_m$ is a diagonal matrix with ones only in the possitions where we actually have observations of $m$.\n",
    "\n",
    "We can then write the normal equations as follows:\n",
    "\n",
    "$\\;\\;\\;Y \\cdot W_u^T \\cdot W_u \\cdot Y^T \\cdot x_u=Y \\cdot W_u^T \\cdot W_u \\cdot r_u^T$\n",
    "\n",
    "and\n",
    "\n",
    "$\\;\\;\\;X \\cdot W_m^T \\cdot W_m \\cdot X^T \\cdot y_m=X \\cdot W_m^T \\cdot W_m \\cdot r_m$\n",
    "\n",
    "since $W_u$ and $W_m$ are just diagonals of only ones and zeros:\n",
    "\n",
    "$\\;\\;\\;Y \\cdot W_u \\cdot Y^T \\cdot x_u=Y \\cdot W_u \\cdot r_u^T$\n",
    "\n",
    "$\\;\\;\\;X \\cdot W_m \\cdot X^T \\cdot y_m=X \\cdot W_m \\cdot r_m$\n",
    "\n",
    "Solving (alternatingly)  for $x_u$ and $y_m$:\n",
    "\n",
    "$\\;\\;\\;x_u= (Y \\cdot W_u \\cdot Y^T)^{-1} \\cdot Y \\cdot W_u \\cdot r_u^T$\n",
    "\n",
    "$\\;\\;\\;y_m= (X \\cdot W_m \\cdot X^T)^{-1} \\cdot X \\cdot W_m \\cdot r_m$\n",
    "\n",
    "Finally, adding regularization:\n",
    "\n",
    "$\\;\\;\\;x_u= (Y \\cdot W_u \\cdot Y^T + \\lambda \\cdot I)^{-1} \\cdot Y \\cdot W_u \\cdot r_u^T$\n",
    "\n",
    "$\\;\\;\\;y_m= (X \\cdot W_m \\cdot X^T + \\lambda \\cdot I)^{-1} \\cdot X \\cdot W_m \\cdot r_m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below implements this algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def als_train(nusers, nmovies, data, k=20, lmbda=1.0):\n",
    "    TOL=1e-16\n",
    "    R=np.zeros((nusers, nmovies))\n",
    "    W=np.zeros((nusers, nmovies))\n",
    "    for i,j,l in data.values:\n",
    "        R[user2Row[i], movie2Col[j]] = l\n",
    "        W[user2Row[i], movie2Col[j]] = 1 if l > 0 else 0\n",
    "    Y=np.random.random((k, nmovies))\n",
    "    Yaux=np.zeros_like(Y)\n",
    "    X=np.zeros((k, nusers))\n",
    "    while(True):\n",
    "        for u in range(nusers):\n",
    "            X[:,u] = np.linalg.inv(Y.dot(np.diag(W[u,:])).dot(Y.T) + lmbda*np.eye(k)).\\\n",
    "                     dot(Y.dot(np.diag(W[u,:])).dot(R[u,:]))\n",
    "        for m in range(nmovies):\n",
    "            Yaux[:,m] = np.linalg.inv(X.dot(np.diag(W[:,m])).dot(X.T) + lmbda*np.eye(k)).\\\n",
    "                        dot(X.dot(np.diag(W[:,m])).dot(R[:,m]))\n",
    "        #print np.sqrt(np.mean(np.power(Y-Yaux,2)))\n",
    "        if np.sqrt(np.mean(np.power(Y-Yaux,2))) < TOL:\n",
    "            break\n",
    "        else:\n",
    "            Y=Yaux\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def als_predict(X, Y, l):\n",
    "    res=[]\n",
    "    for u, m in l:\n",
    "        res.append( np.dot(X.T[user2Row[u],:], Y[:,movie2Col[m]]) )\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to regularization ($\\lambda$), we need also to set the number of features $k$. So, in the following cells, I look for both the best regularization level and number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks=[2,3,4]\n",
    "lmbdas=[0.1, 1.0, 2.0, 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res={}\n",
    "for k in ks:\n",
    "    for l in lmbdas:\n",
    "        X,Y=als_train(Number_Users2, Number_Movies2, train2, k=k, lmbda=l)\n",
    "        yhat=als_predict(X,Y,valid2.values[:,0:2])\n",
    "        y=valid2.values[:,2]\n",
    "        res[(k,l)] = rmse(y,yhat)\n",
    "        print \"(%d, %f) -> %f\" % (k,l,res[(k,l)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=als_train(Number_Users2, Number_Movies2, train2, k=2, lmbda=1)\n",
    "yhat=als_predict(X,Y, test2.values[:,0:2])\n",
    "print rmse(test2.values[:,2], yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
